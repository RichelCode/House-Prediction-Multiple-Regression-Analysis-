
---
title: "House Prices in King County, USA"
subtitle: "Exploring Predictors Using Regression Modeling and Diagnostics"
author: "Richel Charntel Jing Jing"
date: "`r Sys.Date()`"
output: powerpoint_presentation
---

## Slide 1: Introduction and Objective

- **Objective**: Explore and quantify the key factors influencing house prices in King County, WA.
- **Dataset**: Kaggle's King County housing dataset containing 21,613 observations of real estate transactions.
- **Focus**: Investigate the relationships between house price and predictors such as:
  - Continuous variables: `sqft_living`, `bedrooms`, `bathrooms`.
  - Categorical variables: `waterfront`, `grade`.

---

## Slide 2: Exploratory Data Analysis (EDA)

### Key Insights:
- **House Price Distribution**: Right-skewed, with most properties priced below $500,000.
- **Price vs. Square Footage**: Positive correlation with variability due to other factors.
- **Waterfront Properties**: Most homes lack waterfront access.
- **Living Area**: Most homes are moderate in size, though a few large properties influence the mean significantly.
- **Geographic Location**: Higher-priced homes are concentrated in specific areas, likely reflecting desirable neighborhoods or proximity to amenities.

### Visualizations:
```{r, echo=FALSE, fig.width=10, fig.height=6}
library(ggplot2)
library(gridExtra)
library(tidyverse)
library(corrplot)
library(car)
library(tidyr)
library(dplyr)
library(lmtest)
library(MASS)

# Load the dataset
kc_house_data <- read.csv("kc_house_data.csv")

# House Price Distribution
p1 <- ggplot(kc_house_data, aes(x = price)) +
  geom_histogram(bins = 30, fill = "blue", color = "white") +
  labs(title = "House Price Distribution", x = "Price", y = "Count")

# Price vs Square Footage
p2 <- ggplot(kc_house_data, aes(x = sqft_living, y = price)) +
  geom_point(alpha = 0.5) +
  labs(title = "Price vs. Square Footage", x = "Square Footage", y = "Price")

# Waterfront Properties
p3 <- ggplot(kc_house_data, aes(x = as.factor(waterfront))) +
  geom_bar(fill = "purple") +
  labs(title = "Count of Waterfront Properties", x = "Waterfront (1 = Yes, 0 = No)", y = "Count")

# Living Area Distribution
p4 <- ggplot(kc_house_data, aes(x = sqft_living)) +
  geom_histogram(bins = 30, fill = "green", color = "white") +
  labs(title = "Distribution of Living Area", x = "Living Area (sqft)", y = "Count")

# Geographic Price Distribution
p5 <- ggplot(kc_house_data, aes(x = long, y = lat, color = price)) +
  geom_point(alpha = 0.5) +
  scale_color_viridis_c() +
  labs(title = "Geographic Distribution of House Prices", x = "Longitude", y = "Latitude", color = "Price")

# Combine all plots
grid.arrange(p1, p2, p3, p4, p5, nrow = 3)
```

---
Here's the corrected version of your code chunk, streamlined to integrate seamlessly into your R Markdown and included as Slide 3 in a PowerPoint presentation:

---

### **Slide 3: Model Comparison Metrics**

## Slide 3: Model Comparison Table

### Model Comparison Metrics:

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Load necessary libraries
library(dplyr)
library(knitr)

# Ensure date is in the correct format and preprocess the data
kc_house_data <- kc_house_data %>%
  mutate(
    date = as.Date(date, format = "%Y%m%dT%H%M%S"), # Convert to Date format
    year_sold = as.numeric(format(date, "%Y")), 
    month_sold = as.numeric(format(date, "%m")),
    decade_built = floor(yr_built / 10) * 10,
    log_price = log(price) # Add log-transformed price
  )

# Fit a full model for Cook's Distance calculation
full_model_log <- lm(log_price ~ ., data = kc_house_data)

# Calculate Cook's Distance and remove influential points
cooks <- cooks.distance(full_model_log)
threshold <- 4 / nrow(kc_house_data)
influential_points <- which(cooks > threshold)

# Create refined_data and handle missing values
refined_data <- kc_house_data[-influential_points, ] %>%
  drop_na()

# Check if refined_data has valid rows
if (nrow(refined_data) == 0) {
  stop("Refined data has no valid cases after filtering.")
}

# Perform stepwise selection
both_model <- step(
  lm(log_price ~ 1, data = refined_data),
  scope = ~ sqft_living + bathrooms + floors + bedrooms + grade +
    view + waterfront + sqft_lot + condition + yr_built +
    yr_renovated + lat + long + sqft_living15 + sqft_lot15 +
    year_sold + month_sold + zipcode,
  direction = "both"
)

backward_model <- step(
  lm(log_price ~ ., data = refined_data),
  direction = "backward"
)

forward_model <- step(
  lm(log_price ~ 1, data = refined_data),
  scope = ~ sqft_living + bathrooms + floors + bedrooms + grade +
    view + waterfront + sqft_lot + condition + yr_built +
    yr_renovated + lat + long + sqft_living15 + sqft_lot15 +
    year_sold + month_sold + zipcode,
  direction = "forward"
)

# Fit the refined model
model_refined <- lm(
  log_price ~ grade + lat + sqft_living + yr_built +
    sqft_living15 + floors + condition + view +
    year_sold + bathrooms + waterfront,
  data = refined_data
)

# Function to compute model metrics
compute_model_metrics <- function(model, data) {
  sse <- sum(residuals(model)^2)
  r2 <- summary(model)$r.squared
  adj_r2 <- summary(model)$adj.r.squared
  aic <- AIC(model)
  bic <- BIC(model)
  cp <- sse / (var(model$residuals) * (nrow(data) - length(coef(model)))) +
    2 * length(coef(model)) - nrow(data)
  return(data.frame(SSE = sse, R2 = r2, Adj_R2 = adj_r2, AIC = aic, BIC = bic, Cp = cp))
}

# Compute metrics for each model
metrics_forward <- compute_model_metrics(forward_model, refined_data)
metrics_backward <- compute_model_metrics(backward_model, refined_data)
metrics_both <- compute_model_metrics(both_model, refined_data)
metrics_refined <- compute_model_metrics(model_refined, refined_data)

# Combine results into a single table
results <- rbind(
  cbind(Model = "Forward", metrics_forward),
  cbind(Model = "Backward", metrics_backward),
  cbind(Model = "Both", metrics_both),
  cbind(Model = "Refined", metrics_refined)
)

# Display the table
knitr::kable(results, caption = "Model Metrics Comparison")
```

---

  
## Slide 4: Interaction Effects Table

### Interaction Effects Analysis:
```{r 1.11}
# Fit models with interaction terms
model_1 <- lm(log_price ~ . + waterfront:condition, data = refined_data)
model_2 <- lm(log_price ~ . + waterfront:grade, data = refined_data)
model_3 <- lm(log_price ~ . + bathrooms:floors, data = refined_data)
model_4 <- lm(log_price ~ . + sqft_living:condition, data = refined_data)

# Compute metrics for each model
metrics_1 <- compute_model_metrics(model_1, refined_data)
metrics_2 <- compute_model_metrics(model_2, refined_data)
metrics_3 <- compute_model_metrics(model_3, refined_data)
metrics_4 <- compute_model_metrics(model_4, refined_data)

# Combine metrics into a table
interaction_results <- rbind(
  cbind(Model = "Waterfront:Condition", metrics_1),
  cbind(Model = "Waterfront:Grade", metrics_2),
  cbind(Model = "Bathrooms:Floors", metrics_3),
  cbind(Model = "Sqft Living:Condition", metrics_4)
)

# Display the table
knitr::kable(interaction_results, caption = "Interaction Effects Metrics")
```

---

## Slide 5: Diagnostics and Final Model

### Diagnostics:
```{r, echo=FALSE, fig.width=10, fig.height=6}
par(mfrow = c(2, 2))  # Set up a 2x2 grid for plots
plot(model_refined)  # Generate diagnostic plots
```

### Final Model Selection:
- The **refined model** was selected because it demonstrated better performance in terms of:
  - **Metrics:** \( R^2 \), Adjusted \( R^2 \), AIC, and BIC.
  - **Diagnostics:** Addressed most concerns, including residual patterns and influential points.
- **Limitations:** Minor issues persist, such as:
  - Mild heteroscedasticity.
  - Slight deviations from normality in residuals.
  - A few high-leverage points.
- **Conclusion:** The refined model provides a balance between explanatory power and diagnostic validity, making it the most suitable choice for this analysis.
```

